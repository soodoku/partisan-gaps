\documentclass[12pt, letterpaper]{article}
\usepackage[titletoc,title]{appendix}
\usepackage{color}
\usepackage{booktabs}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\definecolor{dark-red}{rgb}{0.75,0.10,0.10}
\definecolor{bluish}{rgb}{0.05,0.05,0.85}

\usepackage[margin=1in]{geometry}
\usepackage[linkcolor=blue,
			colorlinks=true,
			urlcolor=blue,
			pdfstartview={XYZ null null 1.00},
			pdfpagemode=UseNone,
			citecolor={bluish},
			pdftitle={partisan_gap}]{hyperref}

\usepackage[resetlabels,labeled]{multibib}
\newcites{SI}{SI References}
\usepackage{natbib}

\usepackage{float}

\usepackage{geometry}  % see geometry.pdf on how to lay out the page. There's lots.
\geometry{letterpaper} % This is 8.5x11 paper. Options are a4paper or a5paper or other...
\usepackage{graphicx}  % Handles inclusion of major graphics formats and allows use of
\usepackage{amsfonts,amssymb,amsbsy}
\usepackage{amsxtra}
\usepackage{verbatim}
\setcitestyle{round,semicolon,aysep={},yysep={;}}
\usepackage{setspace} % Permits line spacing control. Options are:
%\doublespacing
%\onehalfspace
\usepackage{sectsty}    % Permits control of section header styles
\usepackage{pdflscape}
\usepackage{fancyhdr}   % Permits header customization. See header section below.
\usepackage{url}        % Correctly formats URLs with the \url{} tag
\usepackage{fullpage}   %1-inch margins
\usepackage{multirow}
\usepackage{verbatim}
\usepackage{rotating}
\setlength{\parindent}{3em}

\usepackage[T1]{fontenc}
\usepackage[bitstream-charter]{mathdesign}

\usepackage{chngcntr}
\usepackage{longtable}
\usepackage{adjustbox}
\usepackage{dcolumn}

\usepackage[nameinlink, capitalize, noabbrev]{cleveref}

\def\citeapos#1{\citeauthor{#1}'s (\citeyear{#1})}

\makeatother

\usepackage{footmisc}
\setlength{\footnotesep}{\baselineskip}
\makeatother
\renewcommand{\footnotelayout}{\normalsize \doublespacing}


% Caption
\usepackage[hang, font=small,skip=0pt, labelfont={bf}]{caption}
%\captionsetup[subtable]{font=small,skip=0pt}
\usepackage{subcaption}

% tt font issues
% \renewcommand*{\ttdefault}{qcr}
\renewcommand{\ttdefault}{pcr}


\setcounter{page}{0}

\usepackage{lscape}
\renewcommand{\textfraction}{0}
\renewcommand{\topfraction}{0.95}
\renewcommand{\bottomfraction}{0.95}
\renewcommand{\floatpagefraction}{0.40}
\setcounter{totalnumber}{5}
\makeatletter
\providecommand\phantomcaption{\caption@refstepcounter\@captype}
\makeatother

\title{A Measurement Gap? Effect of Survey Instruments on Partisan Knowledge Gaps}

\author{Lucas Shen \and Gaurav Sood}


\begin{comment}

setwd(paste0(githubdir, "partisan-gaps/ms/"))
tools::texi2dvi("partisan_gap.tex", pdf = TRUE, clean = TRUE)
setwd(githubdir)

\end{comment}

\begin{document}
\maketitle
\thispagestyle{empty}

\begin{abstract}

\noindent Conventional wisdom suggests large, persistent gaps between partisans' stores of political knowledge, fanning concerns about democratic accountability. We reconsider the frequency and size of these ``partisan knowledge gaps,'' in  series of experiments. Our findings suggest that knowledge gaps---when they do exist---stem more from motivated responding than genuine differences in factual knowledge.

\end{abstract}

\vspace{.2in}

\newpage

\doublespacing


%Factual knowledge about politics has long been viewed by scholars as key to democratic competence. Higher levels of political knowledge correspond to a number of normatively desirable outcomes, including higher levels of political tolerance and support for democratic norms, more active participation in politics, and more stable and consistent opinions on political matters \citep{Converse1964,dellicarpini,galston_2001}. Political knowledge also helps facilitate connections between individual group identities and policy views, which can then be applied to evaluations of public officials and parties in a way that increases democratic accountability \citep{dellicarpini}.

%Political knowledge's centrality to democratic health is perhaps why so many are troubled by the fact that Democrats and Republicans appear to differ in their knowledge of politics. Partisans' biased interpretation and retention of political facts appears in public opinion data reaching at least as far back as the 1980s \citep[e.g.,][]{bartels_2002,jerit2012partisan}. As such, the idea of large partisan knowledge gaps---differences in the types of information that Democrats and Republicans know---has become axiomatic in the political science. Indeed, as \citet{bullocketal_2015} note, conventional wisdom in the discipline that ``a persistent pattern in American public opinion is the presence of large differences between Democrats and Republicans in statements of factual beliefs'' (520). Everyday Americans seem to be catching on as well. A poll conducted by the Pew Research Center in 2018 demonstated that nearly eight in ten Americans believe that Democrats and Republicans not only disagree on plans and policies, but on facts as well \citep{pew2018disagree}.

%Large knowledge gaps stemming from partisan biases are concerning. Just as high levels of political knowledge can lead to better citizenship, mass disagreement politically consequential facts can impede democratic governance and representation. Theories of retrospective accountability hinge citizens' ability to judge how well incumbents have performed in office  \citep{fiorina1981retrospective,Key1966,kramer_1971}. If Republicans and Democrats rely upon different sets of facts to make these judgments, elected officials have weaker incentives to work for their constituents. Partisan disagreement about basic facts also reduces the possibility of meaningful dialogue. If Republicans and Democrats disagree about how the economy is doing, a discussion about policies for improving the economy is unlikely to follow.

%Given the long shadow that these gaps cast on the health of democracy, understanding how often and to what extent partisans differ in their knowledge of political facts is vital. To study the issue, we assembled a large dataset of partisan-relevant knowledge items. To do so, we made use of data from three prominent studies on the nature and pervasiveness of partisan knowledge gaps \citep{bullocketal_2015,jerit2012partisan,prior2015you}. We find that partisan knowledge gaps are highly variable, and that large differences in what Democrats and Republicans believe are less common than conventional wisdom suggests. In fact, fewer than one in three partisan knowledge gaps are larger than ten percentage points. In addition, nearly one in three partisan knowledge gaps are in the ``wrong'' direction, that is, partisans know less party-congenial information than their opponents. In addition, more than half of the gaps in the expected direction are not statistically significant at conventional levels, despite large sample sizes. On the whole, the average knowledge gap between Democrats and Republicans is six percentage points.

In a series of experiments, we find that partisan gap reduces to close to 

\newpage

\section*{Two Theories of Partisan Gaps}

Research shows that partisan gaps in political knowledge are wide and widespread \citep{bartels_2002, jerit2012partisan, lodgetaber_2013}. For instance, when Americans were quizzed at the end of Bill Clinton's first term in 1996 about whether the budget deficits increased, decreased, or remained the same, 39\% of Democrats correctly identified that the budget deficit had decreased, only 25\% of Republicans did the same \citep[280]{achen2016democracy}. There are two broad explanations for these gaps. The first is that partisan gaps on partisan consequential knowledge and misinformation items are a result of the fact that partisans know different things. The second theory is that partisans gaps are an artifact of the survey design.


\subsection*{Partisan Gaps in Knowledge}
Partisan gaps in survey measures of political knowledge and misinformation may reflect \emph{actual differences} in what partisans believe. These differences in beliefs may in turn stem from selective exposure to information, which may be because partisans trust different sources of information or because partisans pay attention to different issues, topics, and politicians \citep[e.g.,][]{Stroud2008,stroud_2010}. To the extent that partisan gaps in political knowledge and misinformation stem from different 'tastes' in politics, the gaps are similar to other types of gaps --- see research on gaps in gender \citep{dolan2011women, barabas2014question} and race \citep{abrajano2015reexamining}.

Selective exposure is generally made worse by ``motivated skepticism'' \citep{taber2006, stroud2008media}. People are more skeptical of uncongenial than congenial information and thus may be more likely to follow-up and do the due diligence to disprove an uncongenial fact or may just take uncongenial information to be untrue and move past it. People may be less likely to remember uncongenial information.

When people encounter information that conflicts with their predispositions, they experience cognitive discomfort, which they try to minimize by employing a variety of defense mechanisms \citep[e.g.,][]{abelson1959modes,festinger1962theory}. Specifically, they avoid exposing themselves to sources that provide them with uncongenial information, distrust such information when they do come across it, and do not work as hard to retain it \citep{bartels_2002, jerit2012partisan, lodgetaber_2013}. Partisanship helps reduce cognitive discomfort by acting as a ``perceptual screen,'' filtering in congenial facts that comport with an individual's partisan worldview while filtering out those that challenge it \citep{campbell1960, Zaller1992}. 

To summarize, it is possible that the observed partisan gaps in political knowledge in survey research reflect actually excisiting knowledge gaps, which originate in partisans knowing different things, holding different types of misinformation or being ignorant about different aspects of politics.

\subsection*{Partian Gaps As Artifact of Survey Design}
Partisan gaps on partisan consequential knowledge and misinformation items on surveys may be an \emph{artifact of questionnaire design}. 

One reason why partisan gaps may be inflated is because surveys encourage people to guess when they don't know. Guesses, in turn, cause structured error. Minimally, if we don't adjust for random guessing, guesses cause us to think that more people know the thing than they do. But guesses by partisans on partisan consequential items have a structure to them. Partisans either use affect as a guide to infer the answer. For instance, asked about what happened to the federal deficit during the Obama administration, Republicans, thinking Democrats cause bad things infer that deficits increased under Obama. Alternately, a longer reasoning chain may ensue --- regarding Democrats as generally insouciant about deficits, may infer, without actually knowing, that it increased.  

Surveys also encourage respondents to respond 'expressively,' highlighting partisan motivations than accuracy motivations. \citep{Zaller1992} The latter explanation has attracted a bunch of research. Some research shows that up to half of the partisan gaps are a result of expressive responding \citep{prior, bullock}. Though see Berinsky. 

%That being said, recent scholarship has provided reasons to doubt that these knowledge gaps are as frequent and sizable as commonly believed. For one,  \citet{bullocketal_2015} and \citet{prior2015you} demonstrate that partisan gaps in factual beliefs about politics are often the product of motivated responding. ``Partisan cheerleading'' arises when partisans want to send a message to either pollsters or the public at large about the strength or righteousness of their preferred party's stance on a particular matter \citep{huber_yair_2018}. As a result, what may look like differences in political knowledge among partisans may be more a consequence of respondents providing party-congenial responses rather than expressing what they genuinely know. \citet{bullocketal_2015} and \citet{prior2015you} show that these partisan gaps can be reduced by shifting respondents' directional motives to accuracy motives via small monetary incentives for correct answers. More recently, \citet{huber_yair_2018} also showed that partisan gaps shrink when survey respondents are given the opportunity to cheerlead prior to answering other questions. Taken together, these studies suggest that the concern that Democrats and Republicans are truly drawing on differential bases of political knowledge may be overblown.

\subsection*{Empirical implications of the theories}

To disambiguate between the two explanations, we mount a series of survey experiments. If partisan gaps are a result of actual differences, minor differences in question wording and response options stem should principally have little effect on the gap. On the other hand if the gaps are sensitive to question and response attributes, it suggests that some of the partisan gaps may not be founded in differences in strongly held beliefs. The argument goes that partisan gaps emerge because surveys are designed in a way that encourage respondents to provide answers that are congenial to them even when they don't have strongly held beliefs about the question at hand. Inflationary features --- not including don't know (cite bullock who prices DK), social proof, guessing encouraging, and not accounting for guessing. Our hunch is that if you take out the inflationary features, the partisan gaps go down.

\begin{itemize}

	\item Real World (RW): The RW condition reflects the real-world standards most closely--it does not feature a `Don't Know', it often features social proof about the incorrect answer, for instance, ``Some people believe Barack Obama was not born in the United States, but was born in another country'' on a question about where Mr. Obama was born, and some neutral information about the topic, like ``According to the Constitution, American presidents must be `natural born citizens''' on the birthplace question, that may encourage the ignorant to take a guess.
	
	\item No DK +  SP + GE: It never includes the 'Don't Know,' it always includes neutral information that encourages people to take a guess, and it also includes social proof about the incorrect answer.
	
	\item DK + SP + No GE: The FSR standard adds a `Don't Know’ and removes from the question stem any neutral information that is likely to cause people to offer a substantive response when they don't know.
	
	\item DK + No SP + No GE: The best version of the multiple-choice question---no social proof, no guessing encouraging neutral wording, and a don't know---while maintaining commensurability with other items. 
	
	\item Confidence Scoring: Respondents rate the claim on a 0 to 10 scale going from `definitely false' to `definitely true.' The question is inspired by other attempts to take account of confidence in distinguishing misinformation from incorrect responses stemming from processes like inference, unlucky guessing, and such (see, for instance, \citep{pasek2015}).

\end{itemize}

\newpage
\section*{Partisan Knowledge Gaps (MTurk)}
\subsection*{Data and Research Design}\label{sec:data}

In a first survey on Amazon Mechanical Turk (MTurk) in April 2017, we randomly assigned 1,059 respondents to either closed-ended or truth-scale questions about four items. In the closed-ended version of the survey the participants received five options as answers, including a ``Don't Know'' option. In the truth-scale version of the survey respondents were asked to access the truth of the four statements that were answer options in the closed-ended questions. The question in this section of the survey covered the Afforcable Care Act (2), the effect of greenhouse gases (1), the consequences of president Trump's (then) recent executive order on immigration.
% Delete this section if we are not using the deficit questions in the survey
% We further asked all participants two closed-ended questions about the development of the federal deficit under presidents Bush and Obama. Respondents had the following response options: increased (correct in both cases), remained about the same, descreased, and don't know. Both questions were then followed by a probe.
Participants were randomly assigned to an open-ended follow-up question that asked them why they chose this response or a closed-ended ended version that gave them eight options to choose. The exact question wording for each of the items is presented in \cref{si:mturk2}.

In a second survey on Amazon Mechanical Turk (MTurk) in July 2017, we randomlyassigned 1,253 respondents to one of five conditions—Real World (RW), Iron Pyrite Standard (IP), Fewer Substantive Responses (FSR), 14k Gold Standard (14k), and the 24k Gold Standard (24k). In each condition respondents answered 9 misinformation items, ranging from citizenship and religion of Obama to whether global warming is happening or not. (The exact question wording for each of the items is presented in \cref{si:mturk}.) Respondents assigned to RW and IP saw a simple preface: ``Now here are some questions about what you may know about politics and public affairs,'' while in all the other conditions, they were reassured that it is ok to not know answers to these questions and to commit to not looking up answers or asking anyone and to mark don't know when they don’t know. (Again, see \cref{si:mturk} for the specific wording.)

\begin{center}
	\begin{figure}[t]
		\centering
		\caption{Partisan Gap by Treatment Arm (MTurk)}
		\includegraphics[width=\textwidth]{../figs/partisan-gap-by-item-arm.pdf}
		\label{fig:partisangaps-mturk}
		\caption*{\footnotesize 
			Each point is the estimated gap between Republicans and Democrats for how congenial their responses are to their own party.
			Columns indicate the five different treatment arms described in \nameref{sec:data}. Rows indicate the nine individual survey items described in \cref{si:mturk} plus their average.
			Each point is the estimated $\beta$ from estimating $1\{party\text{-}congenial\, response\}_i = \alpha + \beta Rep_i + \varepsilon_i$ for each of items and each of the five arms.			
			Horizontal bars are 95\% confidence intervals constructed from robust standard errors.
		}
	\end{figure}
\end{center}

We start by summarising the average partisan gap for each survey item and each treatment arm from the MTurk sample. \Cref{fig:partisangaps-mturk} shows the results. Each marker represents how much more congenial the responses of the Republicans are to the Democrats. In the RW treatment arm (first column), the Republicans are, on average, 30 percentage points more likely than the Democrats to have party-congenial responses. The subsequent four columns in \cref{fig:partisangaps-mturk} show that, while the estimated differences in party-congenial responses are precise (the narrow bars), the differences attenuated substantially depending on the treatment arms. 

The attenuation is most pronounced when comparing the RW to the 24k arms (first vs. last columns). In the 24k arm, Republicans are, on average, only about 10 percentage points more likely to have party-congenial responses, a drop larger than 50 percent. \Cref{fig:partisangaps-mturk} therefore gives us the first indication that partisan gaps arise, at least in part, from questionnaire artefacts present in the different survey arms.


\subsection*{Results: MTurk 1}


 \input ../tabs/mturk_hk_mc_likert.tex



\subsection*{Results: MTurk}
We formalize the above observation as follows. We regress the dependent variable, an indicator of whether the response is party-congenial, on the interaction of partisanship and the treatment arm:
\begin{equation}\label{eq:partisangap-mturk}
y_{ijk} = \alpha + \beta (Rep)_i + \gamma (Arm)_k + \delta_k (Rep_i \times Arm_k) + (survey \; item)_j + \varepsilon_{ijk}
\end{equation}
for respondent $i$, survey item $j$, and treatment arm $k$. $\beta$ is the difference in partisan knowledge gaps, which corresponds to \cref{fig:partisangaps-mturk}. A positive estimate suggests that Republicans are more likely than Democrats to have a party-congenial response. We focus on the $\delta$'s, which capture how the different treatment arms affect observed partisan knowledge gaps (difference between columns in \cref{fig:partisangaps-mturk}). The baseline treatment arm is always RW, so $\delta$ captures how the four treatment arms---having the same questions with different questionnaire artefacts---mediates partisan knowledge gaps.
We include the survey item fixed effects to allow each item to elicit some constant amount of partisan gap, if any, from the respondents. Standard errors are clustered at the respondent level.

\begin{figure}[!t]
	\centering
	\caption{Partisan Gap by Treatment Arm: MTurk}
	\includegraphics[width=.55\textwidth]{../figs/mturk-pgag-surveyarms.pdf}
	\label{fig:partisangaps-mturk-reg}
	\caption*{\footnotesize 
		Difference between bars indicates the predicted partisan gap by the treatment arms. 
		Bars reconstructed from the interactions of the Republican indicator with the treatment arms as reported in column (3) of \cref{tab:partisangaps-mturk}.
		The baseline arm is RW.
		Capped vertical bars are 95\% confidence intervals.
	}
\end{figure}


\begin{table}[t] \centering \small \setlength\tabcolsep{0 pt} \setlength{\defaultaddspace}{0pt}
	\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}
	\caption{Partisan Knowledge Gaps: MTurk}
	\label{tab:partisangaps-mturk}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{l*{6}{D{.}{.}{-1}}}
			\toprule
			% https://tex.stackexchange.com/questions/567985/problems-with-inputtable-tex-hline-after-2020-fall-latex-release
			\input ../tabs/mturk-reg-table-fragment.tex
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption*{\footnotesize All models are linear probability models where the dependent variable indicates whether the response to a survey item is congenial to party affiliation. Demographic controls include age cohort, gender, education level (college degree, high school, no high school, post-graduate, and some college), and race (Hispanic, Asian, Black, White, Others). All models include the nine survey item fixed effects. Standard errors are clustered at the respondent level. Significance levels: + 0.1 * 0.05 ** 0.01 *** 0.001.}
\end{table}


\cref{tab:partisangaps-mturk} reports the results from estimating \cref{eq:partisangap-mturk}. Column (1) includes just the Republican variable, which is significant and consistent with conventional wisdom about gaps in partisan knowledge \citep[e.g.][]{bullocketal_2015, pew2018disagree}.
Column (2) includes only the treatment arms, and three of them elicit differences in partisan gaps that are statistically different from the baseline RW arm. While the treatment arm estimates are not as large as the Republican variable in column (1), it is still substantial evidence of how variable the estimated knowledge gap can be in the presence of questionnaire artefacts.

Moreover, it is variable in a way that is independent of partisanship. Without accounting for partisanship, for instance, the average respondent assigned to the 24k arm is 17 percentage points less likely to give a party-congenial response than the RW arm ($p<0.001$). This gap is approximately two-thirds of the estimated effect of partisanship on the partisan knowledge gap.

In column (3) of \cref{tab:partisangaps-mturk}, we include the interaction of partisanship and treatment arms. Now the Republican variable captures the partisan gap in the RW arm (corresponding to column (1) of \cref{fig:baltest-24k-rw}). The Republican and treatment arms interactions reveal the extent to which partisan knowledge gap changes across the different treatment arms. 

\cref{fig:partisangaps-mturk-reg} shows the estimates in absolute terms. For the FSR interaction term, just adding a `Don't Know' response option reduces the estimated partisan knowledge gap by half ($p<0.001$).
The largest reduction is 71 percent ($p<0.001$), which comes from the 24k arm. This arm allows respondents to rate their responses on a 0 to 10 scale from `definitely false' to `definitely true' instead of a false and true option. Including self-reported characteristics of respondents in columns (4)--(6) does not change this conclusion. Overall, the MTurk sample reveals that measured partisan knowledge gaps are highly sensitive to different questionnaire artefacts in the same questions.


\section*{Impact of Partisan Cues on Partisan Gaps}

\subsection*{Partisan Cues}\label{subsec:partisan-cues}
The aim of the study is to present experimental evidence about effect of partisan cues in the question stem on responses by partisans. For the purpose of the study, we examine closed-ended items asking about policy-relevant facts or objective performance, particularly those items stirring affective consistency, stereotyping, or both.  In the first case, items whose correct response option one side or the other would like to disbelieve, or at least one of whose incorrect response options one side or the other would like to believe, or both; in the second case items whose correct response option defies stereotype, or at least one of whose incorrect response options conforms to stereotype, or both.  

For exploring the research question, we exploit two datasets---a national survey conducted by YouGov, and a telephone survey of a random sample of adults in Texas. The YouGov survey interviewed 2000 respondents between July 10th and 12th, 2012.  In Texas, a total of 1003 interviews were conducted between September 10th and 21st, 2012. 

In the YouGov survey, respondents were randomly assigned to factual questions with either a Republican or Democratic cue in the stem. In a question about whether ``since 2010 midterm elections, the unemployment rate [had] gone up, down, or remained the same, or couldn't you say?'', we inserted either the phrase “when Republicans regained control of the U.S. Congress'' or ``when Democrats retained control of the Senate” right after the first phrase. We employed a similar manipulation for the question on budget deficit, asking how the budget deficit had fared “since the 2010 midterm elections, when Republicans regained control of the U.S. Congress (or ``when Democrats retained control of the Senate''), has the budget deficit gone up, gone down, remained the same, or couldn't you say?''

In the Texas survey, we added another condition to the above design – no partisan cue in the stem. So a third of the respondents were assigned to a question that simply read, ``since the 2010 midterm elections, has the unemployment rate gone up, gone down, or remained the same?  Or couldn’t you say?'' For the second question we changed our design to – no partisan cue, Democratic cue, and Democratic cue plus the following introduction “based on what you have heard”. The question read, ``since January 2009, have federal taxes increased, decreased, or remained the same or couldn’t you say?.'' The second version gave respondents a Democratic cue by changing the initial part of the sentence; the question now read, “Since Barack Obama took office\ldots''  The third version prepended a cue designed to encourage guessing to the second version; the version read, “Based on what you have heard, since Barack Obama took office, \ldots''


\subsection*{Results: Partisan Knowledge Gaps with Partisan Cues (YouGov)}
\begin{figure}[t]
	\caption{Partisan Knowledge Gaps with Partisan Cues: YouGov Survey}	
	\centering
	\begin{subfigure}{.495\textwidth}\centering
		\includegraphics[width=\textwidth]{../figs/yougov-unemp-congenialcue.pdf}
		\caption{Unemployment}
	\end{subfigure}
	\hfil
	\begin{subfigure}{.495\textwidth}\centering
		\includegraphics[width=\textwidth]{../figs/yougov-deficit-congenialcue.pdf}
		\caption{Budget deficit}
	\end{subfigure}	
	\caption*{\footnotesize Bars indicate the predicted percent of responses saying that unemployment or the budget deficit have gone up (correct responses) as reported in \cref{tab:partisangaps-yougov} (columns (1) and (4)).  
		Capped vertical bars indicate 95\% confidence intervals.
	}
	\label{fig:yougov-reg}
\end{figure}

We start with the YouGov survey to provide experimental evidence that cues in survey questions can affect responses to questions about policy-relevant and objectively verifiable facts. This survey includes questions about changes in unemployment and the budget deficit since the 2010 midterm elections, with manipulated partisan cues in the stem. 

Using the YouGov survey responses, we estimate
\begin{equation}\label{eq:pgap-yougov}
\text{correct response}_{i} = \alpha + \beta (congenial \; cue)_i  +\varepsilon_{i},
\end{equation}
where the dependent variable is the indicator for whether the response to the question is correct.
As discussed above in \cref{subsec:partisan-cues}, we model the correct response rate as dependent on whether the cue presented to individuals is congenial to responding correctly. Specifically, the congenial cue indicator is coded as one when a Democrat receives a question stem with the cue ``when Republicans gained control of the US congress.'' This cue manipulates Democrats into blaming the Republicans by suggesting that unemployment has gone up, which is the correct response. The reverse happens for Republicans. The congenial cue for Republicans is coded as one when they receive the cue ``When Democrats retained control of the Senate.''

\begin{table}[t] \centering \normalsize \setlength\tabcolsep{0 pt} \setlength{\defaultaddspace}{0pt}
	\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}
	\caption{Partisan Knowledge Gaps with Partisan Cues: YouGov}
	\label{tab:partisangaps-yougov}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{@{\hspace{0\tabcolsep}}l*{6}{D{.}{.}{-1}}@{\hspace{0\tabcolsep}}}
			\toprule
			% https://tex.stackexchange.com/questions/567985/problems-with-inputtable-tex-hline-after-2020-fall-latex-release
			&\multicolumn{3}{c}{Unemployment has gone up}&\multicolumn{3}{c}{Deficit has gone up}\\
			\cmidrule(lr){2-4}\cmidrule(l){5-7} 
			\input ../tabs/yougov-reg-table-fragment.tex
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption*{\footnotesize Dependent variables are indicators for whether the individual responded that unemployment or the budget deficit had gone up since the 2010 midterm elections (which are the correct responses).
		Congenial cue is an indicator of whether the question stem includes the cue towards getting the correct response. For Democrats, this is when the question stem includes the cue ``when Republicans gained control of the US Congress.''
		For Republicans, this is when the question stem includes the cue ``when Democrats retained control of the Senate.''
		Demographic controls include age cohort, gender, education level, marital status, employment status, news interest, family income, and race. Standard errors are heteroskedasticity-robust. 
		All models are linear probability models. 
		Significance levels: + 0.1 * 0.05 ** 0.01 *** 0.001.}
\end{table}
Panel (a) of \cref{fig:yougov-reg} shows that, by manipulating the partisan cue that respondents receive, the probability of getting the correct response for the unemployment question differs by 14 percentage points ($p < 0.001$, reported in \cref{tab:partisangaps-yougov}).

Panel (b) of \cref{fig:yougov-reg} shows that this systematic difference is not unique to the unemployment question. We reestimate \cref{eq:pgap-yougov} where the dependent variable is getting the correct response that the budget deficit has gone up. When the individuals get a congenial cue, they are 18 percentage points more likely to get the correct response ($p<0.001$).
Presumably, we observe this congenial cue effect because the question stem holds the other party responsible for the increase in unemployment and deficit, which are both undesirable.\footnote{\cref{fig:yougov-reg-by-partisanship} show that there is some heterogeneity in how the congenial cue affects Republicans as opposed to Democrats. However, the effect is not unique to either party since partisans of both types are more likely to get the correct response when randomly assigned the congenial cue.}


\subsection*{Results: Partisan Knowledge Gaps with Partisan Cues (Texas Lyceum)}
\begin{figure}[!t]
	\centering
	\caption{Partisan Gap by Treatment Arm: Texas Lyceum, Unemployment}
	\includegraphics[width=.55\textwidth]{../figs/texas-unemp-congenialcue.pdf}
	\label{fig:partisangaps-texas-unemp}
	\caption*{\footnotesize 
		Bars indicate the predicted percent of responses saying that unemployment has gone up (correct response) as reported in column (1) of \cref{tab:partisangaps-texas-unemp}.  
		Capped vertical bars indicate 95\% confidence intervals.
	}
\end{figure}

We further supplement our results with the Texas Lyceum survey, which includes a third cue: a neutral cue. For the question about unemployment in this survey, in addition to congenial and uncongenial cues, individuals can also be randomly assigned a neutral cue where the additional question stem assigning blame to a party is absent, giving us a total of three groups: (i) no cue, (ii) congenial cue, and (iii) uncongenial cue.

\cref{fig:partisangaps-texas-unemp} shows that our results above still hold when we include a neutral cue. Compared to individuals who received a neutral cue, individuals who receive an uncongenial cue are 17 percentage points less likely to get the correct answer that unemployment has gone up ($p<0.001$). Individuals who receive a congenial cue are 8 percentage points more likely to get the correct answer ($p<0.1$). These results are tabulated in \cref{tab:partisangaps-texas-unemp}.

\begin{table}[t] \centering \normalsize \setlength\tabcolsep{6 pt} \setlength{\defaultaddspace}{0pt}
	\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}
	\caption{Partisan Knowledge Gaps with Partisan Cues: Texas Lyceum, Unemployment}
	\label{tab:partisangaps-texas-unemp}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{@{\hspace{0\tabcolsep}}l*{3}{D{.}{.}{-1}}@{\hspace{0\tabcolsep}}}
			\toprule
			% https://tex.stackexchange.com/questions/567985/problems-with-inputtable-tex-hline-after-2020-fall-latex-release
			&\multicolumn{3}{c}{Unemployment has gone up}\\
			\cmidrule(l){2-4}
			\input ../tabs/texas-unemp-reg-table-fragment.tex
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption*{\footnotesize Dependent variable is an indicator for whether the individual responded that unemployment has gone up since the 2010 midterm elections (which is the correct response).
		Congenial cue is an indicator of whether the question stem includes the cue towards getting the correct response. 
		For Democrats, this is when the question stem includes the cue ``when Republicans regained control of the US Congress.''
		For Republicans, this is when the question stem includes the cue ``when the Democrats retained control of the Senate.''
		Demographic controls include age cohort, gender, education level, marital status, number of children, children school enrollment, family income, religion, liberalism/conservatism, and race. Standard errors are heteroskedasticity-robust. 
		All models are linear probability models. 
		Significance levels: + 0.1 * 0.05 ** 0.01 *** 0.001.}
\end{table}


\begin{table}[t] \centering \normalsize \setlength\tabcolsep{6 pt} \setlength{\defaultaddspace}{0pt}
	\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}
	\caption{Partisan Knowledge Gaps with Partisan Cues: Texas Lyceum, Federal Taxes}
	\label{tab:partisangaps-texas-fedtax}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{@{\hspace{0\tabcolsep}}l*{4}{D{.}{.}{-1}}@{\hspace{0\tabcolsep}}}
			\toprule
			% https://tex.stackexchange.com/questions/567985/problems-with-inputtable-tex-hline-after-2020-fall-latex-release
			&\multicolumn{2}{c}{Responded ``Gone up''}&\multicolumn{2}{c}{Responded ``Don't Know''}\\
			\cmidrule(lr){2-3}\cmidrule(l){4-5} 
			\input ../tabs/texas-fedtax-reg-table-fragment.tex
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\caption*{\footnotesize Dependent variables are indicators for whether the individual responded that federal taxes had gone up since the 2010 midterm elections (which are the correct responses) or ``don't know''.
		Congenial cue is an indicator of whether the question stem includes the cue towards getting the correct response. 
		Only Republicans are able to get a congenial cue for these questions.
		This happens when Republicans receive the question stem that includes the cue ``since Barack Obama took office.''
		Separately, individuals can also be assigned a cue that encourages guessing. This happens when the question stem includes ``Based on what you have heard, since Barack Obama took office...''
		Demographic controls include age cohort, gender, education level, marital status, number of children, children school enrollment, family income, religion, liberalism/conservatism, and race. Standard errors are heteroskedasticity-robust. 
		All models are linear probability models. 
		Significance levels: + 0.1 * 0.05 ** 0.01 *** 0.001.}
\end{table}


Finally, we examine the federal taxes question in the Texas Lyceum survey, where individuals are asked whether federal taxes have increased, decreased, or remained the same. For this question, individuals are randomly assigned (i) the Democratic cue ``Since Barack Obama took office'', (ii) the Democratic cue with an additional cue that encourages guessing ``Based on what you have heard, since Barack Obama took office...'', and (iii) a neutral stem.

Based on the estimates in \cref{tab:partisangaps-texas-fedtax}, we observe that randomly receiving a congenial cue still leads to a higher correct response rate of 21.5 percentage points relative to receiving a neutral cue ($p<0.001$). On the other hand, an uncongenial cue leads to a lower correct response of 29.8 percentage points ($p<0.001$).
We also estimate how the cue that encourages guessing affects the ``Don't Know'' response rate. Presumably, a cue that encourages guessing would lead to a lower response rate for Don't Know. We find that the guessing cues do not have a very different effect from cues that do not. 

Overall, we find again using the YouGov survey and Texas Lyceum survey that questionnaire artifacts, via the addition of partisan cues in the same questions, affects the measured gaps in political knowledge. 


\clearpage
\section*{Discussion and Conclusion}

Our results clarify our understanding of partisan knowledge gaps in important ways. The gap in what partisans believe is much smaller than what a naive reading of the survey gaps may suggest. This finding may seem to contradict the literature on selective exposure and motivated reasoning but that research field has also had a reckoning. More recent studies show that most people consume very little political news \citep{Prior2007,flaxmanetal_2016}, and the news that they do consume is relatively ideologically balanced \citep{flaxmanetal_2016,garzetal_2018,gentzkowshapiro_2011,guess_2020}. There is some motivated learning \citep{hill_2017,jerit2012partisan,khanna2018motivated} but the effects are small, and people exhibit little partisan bias in their recall of information \citep{khanna2018motivated}. Other scholars have pointed out that Democrats and Republicans respond to current events in a similar fashion, bringing into question the existence of motivated learning in the first place \citep{gerber_annual_review,kernell_2019}. Therefore, the conventional wisdom regarding the individual-level mechanisms thought to produce large knowledge gaps may be flawed.

One argument is that conventional wisdom is largely based on studies using data from the \citet{anes_gen}. Much of the literature on partisan knowledge gaps has built upon \citet{bartels_2002}, who was the first to write about these differences \citep{bullocklenz_2019}. ANES questions suffer from a series of inflationary features --- 

Based on our results here, we suspect that the vast majority of partisan gaps---when they do appear---are more likely to be a product of motivated responding than of partisans simply knowing different things (\citeauthor{bisgaard_slothuus_2018} \citeyear{bisgaard_slothuus_2018}; \citeauthor {bullocketal_2015} \citeyear{bullocketal_2015}; \citeauthor{prior2015you} \citeyear{prior2015you}; \citeauthor{schaffner_luks} \citeyear{schaffner_luks}; but see \citeauthor{berinsky_2017} \citeyear{berinsky_2017} and \citeauthor{peterson_iyengar_forth} \citeyear{peterson_iyengar_forth}). 

Nor should the small size of the average gap prevent us from noting that on many of the questions, a majority of partisans on both sides of the aisle were either ignorant or misinformed about the facts: the average proportion of Republicans and Democrats who provided correct answers to these knowledge questions is about 42\% each. 

While this is troubling for those who view political knowledge as an essential component of democratic citizenship, there is some reason for optimism. When it comes to knowledge of political facts, more often than not, there do not appear to be large imbalances between what Democrats and Republicans know. When partisan differences do emerge, we suspect that they are often more a product of biased interpretation of survey questions rather than of differential stores of knowledge. This suggests that even in a polarized political context, most Democrats and Republicans can use the same information to make collective judgments about whether to reward or punish elected officials based on performance---whether they want to, of course, is another question. 

\clearpage
\bibliographystyle{apsr}
\bibliography{pgap}

\clearpage

\input{./sections/appendix.tex}


\end{document}